{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c92f49d1-1801-4e9f-afab-d303b9526b41",
   "metadata": {},
   "source": [
    "# 监督微调（Supervised Fine-Tuning）学习笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283afa72-1829-4e78-886c-d630e7e06023",
   "metadata": {},
   "source": [
    "## 一、什么是SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94176d73-eb36-4f0e-8ddc-77890f65d880",
   "metadata": {},
   "source": [
    "**定义：**   \n",
    "监督微调是大预言模型训练的一个重要阶段，指在预训练模型的基础上，使用有标签的特定任务数据对模型进一步训练，使模型适应特定任务和领域。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a05b3-edc8-4bde-82d9-bfe2e0f7b965",
   "metadata": {},
   "source": [
    "**核心思想**  \n",
    "是利用预训练模型学到的通用语言知识，通过在特定任务数据上的进一步训练，让模型学会解决特定问题的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3899c3f9-f755-4da1-a0ec-245c3d2f8072",
   "metadata": {},
   "source": [
    "**工作流程**  \n",
    "加载预训练模型，准备训练数据，模型训练，模型评估，模型部署。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebdff6-1984-4111-b390-41df66fa9b86",
   "metadata": {},
   "source": [
    "**SFT与预训练的区别**  \n",
    "1、数据类型：预训练使用无标签的大规模数据文本，SFT使用有标签的特定任务数据。  \n",
    "2、目标函数：预训练通常使用语言建模目标，SFT使用特定任务的损失函数。  \n",
    "3、训练目标：预训练模型学习通用语言表示能力，SFT学习特定任务能力。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b2e92-a309-4356-97ab-67f0a6569e0f",
   "metadata": {},
   "source": [
    "## 二、LLM预训练与SFT的详细对比："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b2f6b-d42a-4d66-8ffd-438853e22725",
   "metadata": {},
   "source": [
    "**1、数据差异：**  \n",
    "数据规模：LLM通常为TB级别的大规模文本数据，SFT通常为GB级别的指令回答对数据    \n",
    "数据类型：LLM无标签的原始文本数据，采用**自监督学习**，SFT有标签的结构化数据，格式为（指令，期望输出）     \n",
    "数据来源：LLM网页、书籍、新闻、学术论文等多样化来源，SFT人工标注、模型生成后筛选、现有数据集转换     \n",
    "数据特点：LLM通用性强，覆盖面广，旨在学习通用语言规律，SFT针对性强，专注于指令遵循和对话能力  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c89278-91db-49fc-98ac-f5c5fbb5436a",
   "metadata": {},
   "source": [
    "**自监督学习：** 自监督学习是一种利用数据本身构造训练目标（标签）的方法，让模型在没有人工标注的情况下也能进行有效的学习。在大模型中，它主要用于预训练阶段，帮助模型掌握通用语言能力。最常见的是因果语言建模和掩码语言建模。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d39218-29fa-4efe-aa4f-e934b697873a",
   "metadata": {},
   "source": [
    "**2、训练目标差异：**  \n",
    "语言建模：LLM预测下一个词（因果语言建模），SFT学习按照人类指令格式生成响应  \n",
    "目标函数：LLM交叉熵损失，最大化序列的似然概率，SFT监督学习的交叉熵损失  \n",
    "优化目标：LLM学习通用语言表示、世界知识和推理能力，SFT学习对话能力、任务执行能力和安全约束  \n",
    "核心能力：LLM文本生成、语言理解、知识存储，SFT对话交互、多轮问答、指令理解  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52995143-22ce-4289-af63-2a6032390690",
   "metadata": {},
   "source": [
    "**3、训练方式差异：**  \n",
    "训练方式：LLM自监督学习，无需人工标注，SFT监督学习依赖高质量人工标注  \n",
    "训练时长：LLM需要很长时间，SFT较短  \n",
    "计算资源：LLM需要数千张GPU/TPU的大规模并行训练，SFT使用较少计算资源几十张GPU  \n",
    "模型变化：LLM从随机初始化到具备通用智能的基础模型，SFT在预训练基础上调整对话和指令的遵循能力  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fac24e-5316-4089-946d-fa6a91357e7a",
   "metadata": {},
   "source": [
    "## 三、SFT的原因"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927f9fb-0080-4a9a-82b7-ddb92f68ec76",
   "metadata": {},
   "source": [
    "SFT 是实现模型与人类价值观、业务目标对齐的关键步骤。通过人工标注或专家设计的训练数据，引导模型输出更符合人类期望的结果，为后续的 RLHF（基于人类反馈的强化学习）打下基础。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d683266-fb0d-46e9-80c3-9b685b98de07",
   "metadata": {},
   "source": [
    "#### （一）实现指令微调（Instruction Tuning）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b5bab-93c8-4453-88fe-1d2fdca0fd5b",
   "metadata": {},
   "source": [
    "预训练模型虽然具备强大的语言理解与生成能力，但其输出往往缺乏对用户指令的准确理解和响应能力。通过 SFT，使用高质量的指令-响应对进行微调，可以使模型：  \n",
    "1、准确识别用户意图，理解多样化指令；  \n",
    "2、按照指定格式（如问答、列表、JSON 等）生成结构化输出；  \n",
    "3、更好地控制生成行为，提升回复的相关性与一致性；  \n",
    "4、增强安全性和合规性，减少有害、偏见或不合法内容的生成。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66852a09-70a5-4634-898c-f57da0c20df7",
   "metadata": {},
   "source": [
    "#### （二）注入领域专业知识（Domain Adaptation）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3a6c9-7eb7-40f8-a19b-002cbdaf4e8c",
   "metadata": {},
   "source": [
    "SFT 能够将特定领域（如医疗、金融、法律、客服等）的专业知识融入模型，在不牺牲通用语言能力的前提下，显著提升其在垂直任务上的表现。具体包括：  \n",
    "1、学习领域术语、表达习惯和推理逻辑；  \n",
    "2、提高在专业任务（如诊断建议、合同生成、风险评估）中的准确性和可信度；  \n",
    "3、使模型更贴合实际业务场景，增强实用性与落地价值。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ad3b7-b4ee-4cfa-bba0-b3f2398ed484",
   "metadata": {},
   "source": [
    "## 四、指令微调和垂直领域知识注入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f214b-93b3-48a6-9037-dcbfe3a3f908",
   "metadata": {},
   "source": [
    "#### （一）指令微调：  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cdb77a-255b-48ac-9a14-4c46ade4570e",
   "metadata": {},
   "source": [
    "**概念：**  \n",
    "指令微调是指用由指令和其对应的输出组成的数据集来微调模型，是模型学会按照人类的指令执行任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667f5f93-f9a8-4194-b2f0-d711009c3a10",
   "metadata": {},
   "source": [
    "**单任务指令微调：** 专注于让模型掌握特定的任务。    \n",
    "\n",
    "数据格式：特定任务的(指令, 输出)对  \n",
    "目标：使模型精通特定任务类型  \n",
    "应用：专业场景下的高性能任务执行  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf18f3-7a36-41b1-af97-09015e88d566",
   "metadata": {},
   "source": [
    "**多任务指令微调：** 让模型同时学习多种不同类型的任务，提升通用能力。  \n",
    "\n",
    "数据格式：多样化的(指令, 输出)对集合  \n",
    "目标：使模型具备通用任务执行能力  \n",
    "应用：通用AI助手、多场景应用  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0980dba6-450c-4f2c-bc4f-0e55f667e1a6",
   "metadata": {},
   "source": [
    "**指令微调的核心价值：** 使模型任务泛化，能处理没见过的指令类型；能按照不同的格式要求生成响应；保持上下文一致性；确保输出安全和符合伦理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02fccd-e1a9-4176-8f00-47b1a68b377e",
   "metadata": {},
   "source": [
    "#### （二）垂直领域知识注入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9346c7-df82-4d01-bb49-3bc1c6567191",
   "metadata": {},
   "source": [
    "**概念：** 垂直领域知识注入是通过用特定领域的知识进行微调，是模型获得该领域的专业知识和能力。  \n",
    "\n",
    "数据格式：特定领域的专业数据  \n",
    "目标：使模型具备领域专业知识  \n",
    "应用：提升模型在特定领域的表现  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57355b-52f3-45a2-932b-2d698efb0779",
   "metadata": {},
   "source": [
    "#### （三）二者的区别  \n",
    "指令微调和垂直领域知识注入虽然都通过监督微调（SFT）实现，但目标和侧重点不同：指令微调的核心在于提升模型对用户指令的理解与遵循能力，使其能够准确识别意图、按指定格式生成响应、控制输出行为，从而增强通用交互的可靠性与一致性；而垂直领域知识注入则侧重于将特定行业或任务的专业术语、逻辑和知识融入模型，提升其在某一专业领域内的准确性和实用性。简言之，指令微调关注“如何正确地响应指令”，属于**交互能力优化**，而领域知识注入关注“在特定领域知道什么”，属于**内容能力增强**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8063227-b070-4d0c-8c15-5b42068b6957",
   "metadata": {},
   "source": [
    "## 五、大模型的灾难性遗忘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ba217-d2f2-48d8-a75a-03c77a1e84a0",
   "metadata": {},
   "source": [
    "**概念：** 灾难性遗忘指的是模型在学习新任务时，忘记或严重损毁以前学到的旧知识和能力的现象。  \n",
    "**具体表现为：** 通用语言能力退化，在新任务表现良好，旧任务退化严重，原本的知识和能力被覆盖扭曲。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ef1a9-fb74-4021-b90a-bafc776d4c99",
   "metadata": {},
   "source": [
    "#### （一）灾难性遗忘的原因\n",
    "1、参数覆盖：微调过程中新任务的梯度可能覆盖旧任务的重要参数。  \n",
    "2、表示冲突：新旧任务可能由不同的特征表示。  \n",
    "3、优化过程：标准的梯度优化过程没有保护旧知识的机制。  \n",
    "4、数据不可得性：在微调新任务时，通常无法访问原始训练数据，导致模型无法通过回放或联合训练来巩固旧知识，进一步加剧遗忘问题。  \n",
    "5、模型容量与学习率失衡：大模型虽具有较强表达能力，但在微调时若学习率设置过高或微调数据量较小，容易导致参数剧烈变动，使模型快速偏向新任务而忽略通用知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c18be-4cc9-4c34-97f4-14a297ae0777",
   "metadata": {},
   "source": [
    "#### （二）灾难性遗忘的解决方法  \n",
    "**1、多任务学习（Multi-task Learning）**  \n",
    "**核心思想：** 在微调阶段，同时训练模型完成多个任务（包括新任务和旧任务），通过共享表示来平衡不同任务之间的知识学习，避免参数过度偏向某一任务。  \n",
    "**实现方式：** 将来自多个任务的样本混合成统一训练集，每个样本附带任务标识，模型通过联合损失函数进行优化（如加权求和各任务损失）。  \n",
    "**优势：**    \n",
    "有效保留旧任务性能，提升模型泛化能力；  \n",
    "促进任务间知识迁移，增强整体表现。  \n",
    "**局限：**   \n",
    "需要访问所有历史任务的数据，存储和计算成本高；  \n",
    "任务间可能存在冲突，需精细设计损失权重。  \n",
    "**适用场景：**     \n",
    "任务数量有限、历史数据可获取的场景，如医疗诊断中的多病种识别。  \n",
    "\n",
    "**2、弹性权重巩固（Elastic Weight Consolidation, EWC）**  \n",
    "**核心思想：** 识别对旧任务重要的模型参数，并在微调新任务时限制这些参数的变动幅度，从而保护关键知识。\n",
    "**实现方式：** 基于费雪信息矩阵（Fisher Information Matrix）评估每个参数对旧任务的重要性，构造一个正则化项加入新任务的损失函数中：\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\mathcal{L}_{\\text{new}}(\\theta) + \\sum_{i} \\frac{\\lambda}{2} F_i (\\theta_i - \\theta_i^*)^2\n",
    "$$\n",
    "其中$F_i$是参数$\\theta_i$的重要性，$\\mathcal{L}_{\\text{new}}(\\theta)$表示新任务的损失函数，$\\theta_i^*$是旧任务下的最优值，$\\lambda$是正则项系数。  \n",
    "**优势：**  \n",
    "无需回放旧数据，仅需保存旧模型参数和费雪矩阵；  \n",
    "理论基础扎实，能有效缓解参数覆盖问题。  \n",
    "**局限：**    \n",
    "计算和存储费雪矩阵开销较大，尤其对大模型；  \n",
    "对任务顺序敏感，连续多个任务后误差可能累积。  \n",
    "**适用场景：** 连续学习、增量学习任务，如语音助手不断学习新指令。  \n",
    "\n",
    "**3、渐进式学习（Progressive Learning）**   \n",
    "**核心思想：** 逐步引入新任务，给模型适应时间。不修改已有网络结构，而是为每个新任务创建新的子网络，并通过横向连接（lateral connections）复用旧网络的特征表示（将旧列对应层的输出作为输入传给新列，方便新列提取特征），实现知识迁移而不干扰原有知识。  \n",
    "**实现方式：** 每次新增任务时扩展模型结构，冻结旧网络参数，新网络从旧网络各层接收输入（通过可学习的门控机制），联合训练新部分。  \n",
    "**优势：**    \n",
    "完全避免参数覆盖，旧任务知识永久保留；  \n",
    "支持灵活的任务扩展。  \n",
    "**局限：**  \n",
    "模型体积随任务数量线性增长，资源消耗大；  \n",
    "难以部署到资源受限环境。  \n",
    "**适用场景：** 任务差异大、需长期累积学习的系统，如机器人在不同环境中的持续适应。  \n",
    " \n",
    "**4、知识蒸馏（Knowledge Distillation）**   \n",
    "**核心思想：** 利用原始模型（教师模型，大模型）在旧任务上的输出作为“软标签”，指导新模型（学生模型，小模型）在学习新任务的同时模仿大原始模型的旧行为，从而保留旧知识。  \n",
    "**实现方式：** 在微调新任务时，损失函数由两部分组成：  \n",
    "$$\n",
    "\\mathcal{L} = \\alpha \\cdot \\mathcal{L}_{\\text{new}}(y, \\hat{y}) + (1 - \\alpha) \\cdot T^2 \\cdot \\mathcal{L}_{\\text{distill}}\\left(\\sigma\\left(\\frac{z}{T}\\right), \\sigma\\left(\\frac{z_{\\text{old}}}{T}\\right)\\right)\n",
    "$$\n",
    "其中，  \n",
    "$\\mathcal{L}_{\\text{new}}$: 是新任务的监督损失（交叉熵）  \n",
    "$\\mathcal{L}_{\\text{distill}}$: 蒸馏损失，通常为KL散度  \n",
    "$z,z_{old}$: 是学生模型和教师模型的 logits 输出  \n",
    "$\\sigma()$: 是softmax函数  \n",
    "$T$: 温度系数（temperature），用于软化输出分布  \n",
    "$\\alpha$：平衡新任务损失与蒸馏损失的超参数  \n",
    "$T^2$：常见的缩放因子，在 KL 散度损失中用于保持梯度尺度稳定  \n",
    "**优势：**  \n",
    "无需保留旧数据，只需保存教师模型；  \n",
    "可与其他方法（如LoRA）结合使用。  \n",
    "**局限：**    \n",
    "蒸馏过程可能引入噪声，尤其当新旧任务差异大时；  \n",
    "输出空间需一致，难以处理任务类别变化的情况。  \n",
    "**适用场景：** 模型压缩、持续学习、领域迁移等。  \n",
    "\n",
    "**5、正则化技术**  \n",
    "**核心思想：** 在优化过程中引入约束项，限制模型参数偏离旧状态的程度，防止剧烈更新导致的知识丢失。  \n",
    "**常见方法：**  \n",
    "EWC（如上所述）  \n",
    "SI (Synaptic Intelligence)：在线估计参数重要性，动态调整正则化强度；    \n",
    "L2 正则化 / 权重衰减：简单但效果有限，倾向于整体抑制参数变化。    \n",
    "**优势：**  \n",
    "实现简单，计算开销小；  \n",
    "适合轻量级微调场景。  \n",
    "**局限：**  \n",
    "正则化强度难以调优，过强则阻碍新知识学习，过弱则无法防遗忘；  \n",
    "假设旧任务知识集中在少数参数上，可能不适用于高度共享的表示。  \n",
    "**适用场景:** 参数高效微调（如Adapter、LoRA）中的辅助策略。  \n",
    "\n",
    "**6、数据重放（Experience Replay）**  \n",
    "**核心思想：** 通过保存少量旧任务的样本或生成代表性数据，在训练新任务时与新数据混合回放，使模型持续“复习”旧知识。  \n",
    "**实现方式：**  \n",
    "真实样本回放：维护一个小型缓冲区（replay buffer），存储旧任务的代表性样本；  \n",
    "生成式回放：使用生成模型（如GAN、VAE或小型语言模型）合成旧任务的数据分布。  \n",
    "**优势：**  \n",
    "效果显著，能有效维持旧任务性能；  \n",
    "实现直观，易于集成到现有训练流程中。  \n",
    "**局限：**  \n",
    "需要额外存储空间（真实数据）或额外模型（生成模型）；  \n",
    "生成数据可能失真，影响训练稳定性。  \n",
    "**适用场景：** 持续学习、终身学习系统，如智能客服不断学习新业务知识。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bcc1f-5133-40a1-a9e9-8147eec85bac",
   "metadata": {},
   "source": [
    "## 六、大模型的复读现象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e4b18-a650-4d5e-b46b-322b9cbe33b1",
   "metadata": {},
   "source": [
    "**概念：**  \n",
    "复读现象指的是大模型在生成文本时重复生成相同相似的文本，无法产生多样化和创新的输出，具体表现为字，词，短语，句，段落级别的重复。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b3f80-9043-4685-a00f-824c6d20f957",
   "metadata": {},
   "source": [
    "#### （一）复读现象的原因  \n",
    "\n",
    "**1、训练数据偏差与模式固化：**  \n",
    "**高频模式内化：** 训练数据中存在大量重复表达（如新闻标题、社交媒体口号、教程模板），模型将“重复”视为一种高概率、高安全性的语言模式进行学习。  \n",
    "**多样性匮乏：** 某些主题或领域的数据表达方式单一，导致模型学到的“正确回答”模式有限，缺乏多样化的表达策略。  \n",
    "**过拟合：** 模型过度记忆训练数据中的特定短语或句式，而非学习其背后的语义规律，导致在新输入下仍机械复现旧模式。  \n",
    "**领域偏移（Domain Shift）：** 当输入问题超出训练数据分布时，模型因缺乏相关知识，倾向于反复强调问题中的关键词以“填充内容”。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0144fb9-9ef7-43d2-8862-0083ea2c88a2",
   "metadata": {},
   "source": [
    "**2、解码策略的局限性：**  \n",
    "**贪婪搜索（Greedy Search）：** 总是选择概率最高的 token，极易陷入“高概率词循环”，例如反复输出“非常重要”。  \n",
    "**束搜索（Beam Search）保守性：** 追求全局概率最大，倾向于生成流畅但单调的文本，抑制了创造性表达。  \n",
    "**温度过低：** 概率分布尖锐化，强化高概率词，抑制多样性。  \n",
    "**Top-k/Top-p 值过小：** 候选集过窄，模型选择空间受限。  \n",
    "**缺乏重复惩罚机制：** 未显式抑制已生成 token 的再次出现  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ce061-d338-480d-b370-56368332782a",
   "metadata": {},
   "source": [
    "**3、模型置信度失衡和分布概率异常：**  \n",
    "**过度自信（Overconfidence）：** 模型对某些 token 赋予异常高的概率，导致其在后续生成中持续被选中。  \n",
    "**长尾分布抑制：** 模型倾向于忽略低频但合理的表达方式，导致输出集中在少数“安全”选项。  \n",
    "**语义坍缩（Semantic Collapse）：** 不同输入映射到相似的隐状态表示，导致模型输出趋同，缺乏区分度。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7ac56-7d64-4fd2-8d4a-c0ce0f6cc657",
   "metadata": {},
   "source": [
    "**4、注意力机制的局限性：**  \n",
    "**输入词元的过度关注：** 自注意力机制可能对 prompt 中的关键词持续赋予高注意力权重，导致模型不断回指这些词。  \n",
    "**自生成文本的循环强化：** 模型在生成过程中，对自己刚输出的词给予高注意力，形成“自我回声”效应。  \n",
    "**注意力稀释问题：** 在长文本生成中，注意力分布可能变得分散或僵化，难以动态调整关注点。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e466d-1537-4c26-865f-45e42b4232d8",
   "metadata": {},
   "source": [
    "**5、缺乏规划与状态追踪能力：**  \n",
    "**无显式记忆机制：** 基础 LLM 无专门模块记录“已说内容”，依赖上下文窗口隐式记忆，易遗忘或重复。  \n",
    "**无任务分解能力：** 面对复杂问题，无法像人类一样拆解步骤、设定子目标，只能反复陈述问题或泛泛而谈。  \n",
    "**无全局结构规划：** 生成是局部最优的累积，而非基于整体大纲的推进，导致逻辑跳跃或原地打转。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f00ea-bfa9-4e4f-9d51-1f5f6229ce9a",
   "metadata": {},
   "source": [
    "**6、训练目标与评估指标的误导：**  \n",
    "**最大似然估计（MLE）的固有缺陷：** 训练目标是最大化正确 token 的概率，鼓励模型输出“最常见”而非“最优质”或“最多样”的回答。  \n",
    "**缺乏多样性奖励：** 训练过程中未显式鼓励新颖表达，模型无动力探索低概率但合理的输出。  \n",
    "**评估指标偏向流畅性：** BLEU、ROUGE 等指标更看重与参考文本的重合度，间接鼓励复读训练数据中的表达。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76f1ea-2bfb-4e9c-a26e-810bff308f2e",
   "metadata": {},
   "source": [
    "#### （二）解决复读现象的方法\n",
    "\n",
    "**1、惩罚重复机制：**  \n",
    "**原理：**  \n",
    "该方法通过在解码过程中对已经生成过的token施加概率惩罚，降低其再次被选中的可能性，从而避免重复。\n",
    "**实现方式：**  \n",
    "在每一步生成时，检查当前候选词是否已在已生成的序列中出现过。  \n",
    "若出现过，则将其在 logits（未归一化的预测分数）上乘以一个小于1的系数（如0.9），或直接减去一个惩罚值。  \n",
    "常见实现如 Hugging Face 的 transformers 库中的 repetition_penalty 参数。  \n",
    "**优点：**  \n",
    "实现简单，效果显著，尤其对短语级重复有良好抑制作用。  \n",
    "可调节惩罚强度，灵活适应不同任务。  \n",
    "**缺点：**  \n",
    "惩罚过强可能导致语义不通或生成僵硬。  \n",
    "无法区分“合理重复”（如修辞强调）与“病态复读”。  \n",
    "\n",
    "**2、N-gram阻止：**   \n",
    "**原理：**  \n",
    "通过禁止生成与前面已出现的连续N个词元（即N-gram）完全相同的片段，来防止局部重复。  \n",
    "**实现方式：**  \n",
    "维护一个滑动窗口，记录最近生成的 N-1 个词元。  \n",
    "在生成下一个词时，若某个候选词会导致形成一个已出现过的 N-gram，则将其概率设为负无穷（即禁止生成）。  \n",
    "常见设置为 2-gram 或 3-gram 阻止。  \n",
    "**优点：**  \n",
    "有效防止短语或句子片段的机械重复。  \n",
    "特别适用于摘要、翻译等需要简洁表达的任务。  \n",
    "**缺点：**  \n",
    "可能误伤合理重复（如诗歌、排比句）。  \n",
    "N 值选择需谨慎：N 过小控制力弱，N 过大可能过度限制生成空间。  \n",
    "\n",
    "**3、温度采样调整：**  \n",
    "**原理：**  \n",
    "温度用于调节 softmax 输出概率分布的“平滑度”。通过调整温度值，可以改变生成的随机性。  \n",
    "**机制：** \n",
    "高温（T > 1.0）： 概率分布更平坦，增加多样性，降低对高概率词的偏好，有助于跳出重复。  \n",
    "低温（T < 1.0）： 概率分布更尖锐，模型更确定、更保守，容易陷入重复或生成模板化内容。  \n",
    "典型值： T = 1.0 为标准 softmax；T = 0.7~0.9 常用于平衡创造性和稳定性。  \n",
    "**优点：**   \n",
    "简单有效，影响整体生成风格。  \n",
    "高温可增强多样性，减少确定性路径上的重复。  \n",
    "**缺点：**  \n",
    "高温可能导致语义混乱或不连贯。  \n",
    "不能精准控制局部重复，属于全局性调节。  \n",
    "\n",
    "**4、使用Top-p/Top-k采样：**  \n",
    "**原理：**    \n",
    "限制每一步采样时考虑的候选词数量，避免模型总是选择概率最高的几个词，从而减少陷入重复循环的风险。  \n",
    "**具体方法：**   \n",
    "Top-k 采样：  \n",
    "仅从概率最高的 k 个词中进行采样。  \n",
    "k 小：生成更确定但可能重复（如 k=1 退化为贪心搜索）。  \n",
    "k 大：更随机，多样性高。  \n",
    "\n",
    "Top-p 采样（Nucleus Sampling）：  \n",
    "从累积概率超过 p（如 p=0.9）的最小词集进行采样。    \n",
    "动态调整候选集大小，更灵活。    \n",
    "避免固定 k 值的僵化问题。  \n",
    "\n",
    "**优点：**    \n",
    "显著提升生成多样性，打破“高概率词垄断”导致的重复。  \n",
    "Top-p 尤其适合处理长尾分布，保持语义合理性。  \n",
    "**长尾分布：** （Long-tail Distribution）是一种常见的统计分布现象，指的是在某个数据集中，少数项目出现频率非常高（头部），而绝大多数项目出现频率非常低，但种类极多（尾部）。  \n",
    "**缺点：**  \n",
    "参数选择影响大，需调优。  \n",
    "若设置不当，可能导致生成内容偏离主题。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00f5e1-5569-4f37-8596-67b7de8b4cfa",
   "metadata": {},
   "source": [
    "## 七、大模型的幻觉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849e3fe-4087-47fb-8849-7901e7d9ada7",
   "metadata": {},
   "source": [
    "**概念：**  \n",
    "幻觉是指模型生成看似合理，但实际上虚构或者错误的信息的现象。这些信息可能在语法和语义上正确，但与事实不符。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c912f-9b9f-46ed-a2e6-0c8f66b89335",
   "metadata": {},
   "source": [
    "幻觉类型可以分为：事实性幻觉，逻辑性幻觉，指令性幻觉（生成与用户指令不符合的内容），引用型幻觉（虚构引用来源）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963e47a-5fc0-44c3-a814-4c11f9c51c0b",
   "metadata": {},
   "source": [
    "#### （一）幻觉产生原因 \n",
    "\n",
    "**1、数据层面：**    \n",
    "这是幻觉的根源之一。大模型依赖海量数据进行训练，但如果数据本身存在错误、偏见、过时或不完整，模型就会学习并复现这些缺陷。    \n",
    "**2、模型架构与训练目标：**    \n",
    "大模型的核心任务是预测下一个词（token），其目标是生成语法通顺、符合语言习惯的文本，而非验证事实的真伪。这种“概率驱动”的生成机制，使得模型可能为了追求文本的连贯性而牺牲准确性，从而产生事实性错误。  \n",
    "**3、推理与生成策略：**  \n",
    "在生成文本时，模型采用自回归方式逐词生成。一旦早期生成了错误的词，后续内容会基于这个错误继续生成，导致错误累积和扩大。此外，一些旨在增加多样性的生成策略（如随机采样）也可能引入不准确的内容。  \n",
    "**4、外部输入与任务特性：**  \n",
    "用户的提问如果存在歧义或指向不明确，模型可能基于错误的假设进行回答。同时，对于开放性问题或需要复杂推理的问题，模型也更容易因知识边界或逻辑链条的断裂而产生幻觉。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab88933-69cb-4569-8f50-356eed900888",
   "metadata": {},
   "source": [
    "#### （二）缓解幻觉的方法  \n",
    "**1、检索增强生成（RAG）：**  \n",
    "RAG通过在生成回答前从外部知识库中检索相关信息，将真实、可信的上下文注入到模型输入中，从而减少模型凭空编造内容的可能性。该方法结合了信息检索与文本生成的优势，使模型的回答基于实际证据，显著降低事实性错误和虚构内容的产生。  \n",
    "\n",
    "**2、事实校验机制：**   \n",
    "在模型生成内容后，引入自动化的事实校验模块进行后处理验证    \n",
    "**该机制可通过以下方式实现：**    \n",
    "**交叉验证：** 将生成的内容与多个独立来源进行比对，判断一致性；  \n",
    "**实体链接与知识图谱查询：** 识别生成文本中的关键实体（如人名、地点、事件），并在知识图谱中验证其关系是否成立；  \n",
    "**使用判别式模型或专用校验模型：** 训练专门用于判断陈述真实性的辅助模型，对生成结果进行打分或修正。  \n",
    "  \n",
    "**3、prompt限制：**  \n",
    "通过精心设计提示词来引导模型行为，减少幻觉发生。  \n",
    "**具体策略包括：**  \n",
    "**明确指令：** 要求模型“只根据已知信息回答”“不确定时请说明不知道”；  \n",
    "**角色设定：** 赋予模型“谨慎的专家”等角色，增强其保守性和责任感；  \n",
    "**结构化输出格式：** 限定回答格式（如“答案+依据来源”），促使模型区分事实与推测；  \n",
    "**思维链（Chain-of-Thought）引导：** 让模型逐步推理，暴露逻辑过程，便于识别潜在错误。  \n",
    "\n",
    "**4、解码策略优化：**  \n",
    "在生成文本时调整解码算法和参数，控制输出的创造性和确定性之间的平衡：  \n",
    "**降低温度值（Temperature）：** 使用较低的temperature（如0.2~0.7）使模型倾向于选择概率最高的词汇，减少随机性和臆测；  \n",
    "**采用束搜索（Beam Search）或采样约束：** 优先探索高概率路径，避免低置信度输出；  \n",
    "**引入重复惩罚与一致性过滤：** 防止模型自相矛盾或重复无意义内容；  \n",
    "**Top-k / Top-p（Nucleus Sampling）调节：** 合理设置采样范围，在多样性和准确性之间取得平衡。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c492e3-1493-489b-8def-bbccd588bec7",
   "metadata": {},
   "source": [
    "## 八、SFT的损失函数选择  \n",
    "\n",
    "根据任务类型，数据特点，模型目标来选择模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c669a16-5542-4215-9b43-ab5559c290da",
   "metadata": {},
   "source": [
    "#### （一）SFT损失函数最常见的形式，交叉熵损失：\n",
    "**表达式：** \n",
    "$$\n",
    "\\mathcal{L}(\\theta) = -\\sum_{t=1}^{T} \\log P(y_t \\mid y_{<t}, \\mathbf{x}; \\theta)\n",
    "$$\n",
    "$\\theta$是模型参数，  \n",
    "$x$是输入序列，  \n",
    "$y_1,y_2...$是目标输出序列，  \n",
    "$y<t$表示在时间步t之前已生成的输出标记，  \n",
    "$ P(y_t \\mid y_{<t}, \\mathbf{x}; \\theta)$是模型在给定输入和历史输出的条件下，预测第t个标记的概率。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f25bca-4077-47b9-a134-3632499fa264",
   "metadata": {},
   "source": [
    "#### (二）损失函数的变体  \n",
    "**1、加权损失：**   \n",
    "对不同位置不同类型的token使用不同的权重。  \n",
    "\n",
    "**2、聚焦损失（Focal Loss）：**  \n",
    "**表达式：**\n",
    "$$\n",
    "\\mathcal{L}_{\\text{focal}} = -\\sum_{t=1}^{T} (1 - P(y_t \\mid y_{<t}, \\mathbf{x}; \\theta))^\\gamma \\log P(y_t \\mid y_{<t}, \\mathbf{x}; \\theta)\n",
    "$$\n",
    "其中，  \n",
    "$P(y_t \\mid y_{<t}, \\mathbf{x}; \\theta)$是模型对t标记的预测概率  \n",
    "$\\gamma>0$是聚焦参数，通常取2,5  \n",
    "**特点是：**  \n",
    "模型对某一个标签特别自信，会使得标签概率趋近于1，则$1-p(y_t)^{\\gamma}$趋近于0，损失被降低。  \n",
    "反之，损失会被提高，使得模型对该标记进一步学习，有效缓解了高频词“主导”训练过程的问题，提升对低频、关键词的关注。  \n",
    "\n",
    "**3、标签平滑（Label Smoothing）：**  \n",
    "**表达式：**  \n",
    "$$\n",
    "\\mathcal{L}_{\\text{ls}} = -\\sum_{t=1}^{T} \\sum_{v \\in V} \\left[ (1 - \\alpha) \\cdot \\mathbf{1}(v = y_t) + \\alpha \\cdot \\frac{1}{|V|} \\right] \\log P(v \\mid y_{<t}, \\mathbf{x}; \\theta)\n",
    "$$\n",
    "其中，  \n",
    "$V$是词汇表  \n",
    "$\\mathcal{L}_{\\text{ls}}$表示标签平滑后的损失函数    \n",
    "T是序列长度      \n",
    "$v$是词汇表中的某个标记。    \n",
    "$y_t$是时间步t的真实标记。    \n",
    "$(1 - \\alpha) \\cdot \\mathbf{1}(v = y_t)$是指示函数，当v等于$y_t$时值为 1，否则为 0。  \n",
    "$P(v \\mid y_{<t}, \\mathbf{x}; \\theta)$是模型预测的在给定输入序列x和之前标记y<t条件下标记 v出现的概率。  \n",
    "$\\sigma$是平滑因子，取值范围在 [0, 1] 之间,$\\sigma$控制了原始标签和均匀分布之间的平衡，常见的取值是 0.1。  \n",
    "**对于每一个时间步的真实标签t,其目标分布被修改为：**\n",
    "$$\n",
    "q(v) = \n",
    "\\begin{cases} \n",
    "1 - \\alpha + \\dfrac{\\alpha}{|V|}, & v = y_t \\\\[2ex]\n",
    "\\dfrac{\\alpha}{|V|}, & v \\neq y_t \n",
    "\\end{cases}$$\n",
    "这意味着对于正确的标记 $y_t$，其目标概率不再是 1，而是 $1 - \\alpha + \\dfrac{\\alpha}{|V|}$，减少了模型对正确标记的确信度。  \n",
    "对于错误的标记 $v \\neq y_t$，它们各自获得了一个小的非零概率 $\\dfrac{\\alpha}{|V|}$，这表示了一种“不确定”或“可能性”的概念，即使模型认为某些不正确的答案也有可能性，但概率非常低。  \n",
    "**作用是：**  \n",
    "减少过拟合，提高模型的泛化能力，避免过度自信，提升文本生成质量  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d6fe6-4dc4-4576-a212-b35c7a4bb613",
   "metadata": {},
   "source": [
    "## 九、SFT效果的评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93d1f8-7c06-41ad-a0b3-376d88f91ab3",
   "metadata": {},
   "source": [
    "**SFT的评估维度有：** 任务性能，是否保持通用能力（灾难性遗忘），生成质量如何，是否遵循用户指令按照格式输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9cf362-9a25-4df1-b1bb-3967787d5362",
   "metadata": {},
   "source": [
    "**评估方法分为：** 自动评估，人工评估，对比评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef1145-c65c-4172-a30a-cc69634e02ac",
   "metadata": {},
   "source": [
    "#### （一）SFT的评估指标  \n",
    "**1、任务特定指标：**  \n",
    "分类任务：准确率、精确率、召回率、F1分数  \n",
    "生成任务：BLEU、ROUGE、METEOR等  \n",
    "问答任务：EM（Exact Match）、F1分数  \n",
    "**2、通用能力指标：**  \n",
    "语言理解能力测试（如GLUE、SuperGLUE）  \n",
    "常识推理能力测试  \n",
    "**3、质量评估指标：**  \n",
    "困惑度（Perplexity）  \n",
    "重复率  \n",
    "一致性评分  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42da61-7fd0-4abd-96e5-8e4d98831475",
   "metadata": {},
   "source": [
    "#### （二）评估流程  \n",
    "标准评估流程：  \n",
    "1. 准备测试集：收集或构建测试数据集  \n",
    "2. 基线测试：测试预训练模型在测试集上的表现  \n",
    "3. 微调模型测试：测试SFT后模型的表现  \n",
    "4. 指标计算：计算各项评估指标  \n",
    "5. 结果分析：分析微调效果和存在的问题  \n",
    "6. 迭代优化：根据评估结果调整微调策略  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85cd197-8d19-4392-a264-9d359e5d918a",
   "metadata": {},
   "source": [
    "#### （三）BLEU评估指标（Bilingual Evaluation Understudy）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe5566-24b3-4166-b06a-8047c55bf3c3",
   "metadata": {},
   "source": [
    "**定义：** 通过计算生成文本和评估文本之间的n-gram重叠来进行评估\n",
    "**表达式：**\n",
    "$$\n",
    "BLEU=BP\\cdot exp(\\sum_{n=1}^N\\cdot w_n\\cdot log(p_n))\n",
    "$$\n",
    "其中    \n",
    "exp() 是指数函数    \n",
    "Σ 表示求和，通常n从1到N（例如N=4，即计算1-gram到4-gram）。  \n",
    "wₙ 是第n个n-gram的权重，通常取等权重，即 wₙ = 1/N。  \n",
    "**pₙ 是修正的n-gram精确度 (Modified n-gram Precision)，** pₙ = (所有n-gram的修正后匹配总数) / **(生成句子中n-gram的总数)。**  \n",
    "【修正表示的是：为了避免作弊（比如生成一堆高频词如“the the the”来获得高分），BLEU对每个n-gram在生成句子中的出现次数进行了上限限制。这个上限是该n-gram在所有参考译文中出现次数的最大值】  \n",
    "**BP 是 短句惩罚 (Brevity Penalty)：**    \n",
    "设 c 为生成句子的长度（词数）。  \n",
    "设 r 为最接近生成句子长度的参考译文的长度（如果有多个参考译文，选择那个与c最接近的r）。  \n",
    "BP = 1,                  if c > r   \n",
    "BP = exp(1 - r/c),       if c ≤ r "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bb8e0-c2ac-4a17-b4e9-ee6acac63b3a",
   "metadata": {},
   "source": [
    "**适用场景：**  \n",
    "1、机器翻译任务   \n",
    "2、文本生成任务，特别是生成长度与参考文本相近的情况  \n",
    "3、需要衡量生成文本准确性的场景   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c83e0-f1cc-41cf-b596-0c489651aef7",
   "metadata": {},
   "source": [
    "#### (四）ROUGE评估指标（Recall-Oriented Understudy for Gisting Evaluation）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2a394-46a2-4501-bca3-8fbdf1ee79ac",
   "metadata": {},
   "source": [
    "**定义：** ROUGE是一系列用于评估自动摘要质量的指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59fe85-b1b0-4d4c-a2ca-7f43a859af1a",
   "metadata": {},
   "source": [
    "**ROUGE的多种类型：**  \n",
    "**1、ROUGE-N:(基于 n-gram 的召回率)**  \n",
    "计算公式：ROUGE-N = (生成文本与参考文本匹配的 n-gram 总数) / **(参考文本中 n-gram 的总数)**  \n",
    "意义：ROUGE-N 越高，说明生成的摘要在词语组合层面与参考摘要越相似，覆盖了更多的关键短语。\n",
    "\n",
    "**2、ROUGE-L(基于最长公共子序列 - LCS)**\n",
    "定义：L 代表 Longest Common Subsequence。它不局限于连续的 n-gram，而是寻找生成文本和参考文本之间最长的公共词序列，且这个序列中的词在两个文本中出现的顺序必须一致，但不一定连续。     \n",
    "优势：能捕捉句子级别的相似性，对词语顺序更敏感。对同义词替换、句式变换等有更强的鲁棒性（相比 ROUGE-N）  \n",
    "计算公式：  \n",
    "ROUGE-L 实际上计算的是 F1 分数，结合了基于 LCS 的召回率和精确率。\n",
    "lcs = 最长公共子序列的长度，m = 生成文本的长度（词数），n = 参考文本的长度（词数）\n",
    "ROUGE-L Recall = lcs / n\n",
    "ROUGE-L Precision = lcs / m\n",
    "ROUGE-L F1 = (2 * Recall * Precision) / (Recall + Precision)  \n",
    "意义：ROUGE-L 能很好地评估生成文本是否抓住了参考文本的核心语义和主要事件流。  \n",
    "\n",
    "**3、ROUGE-S（Skip-Bigram Co-occurrence Statistics）**  \n",
    "定义：S 代表 Skip-Bigram。Skip-bigram 是指文本中间隔任意数量词的任意两个词组成的词对（顺序重要）。  \n",
    "表达式：ROUGE-S = (匹配的 skip-bigram 总数) / (参考文本中 skip-bigram 的总数)【同样使用修正计数】  \n",
    "意义：ROUGE-S 能捕捉更远距离的词语共现关系，对句子的灵活性要求更低，能更好地评估语义相似性。  \n",
    "\n",
    "**4、ROUGE-W (Weighted LCS)**  \n",
    "定义：W 代表 Weighted。它是对 ROUGE-L 的改进，认为连续匹配的子序列比非连续的、跳跃的匹配更重要。它会给更长的连续匹配赋予更高的权重。  \n",
    "思想：如果两个文本有一段连续的词完全相同，这比相同数量的词但分散在各处更能说明相似性。  \n",
    "计算：使用一种加权的动态规划算法来计算 LCS，连续匹配的得分更高。  \n",
    "意义：比标准 LCS 更强调“流畅性”和“局部一致性”。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c5c59f-8ce1-432f-b42f-c3d5bc2625ed",
   "metadata": {},
   "source": [
    "**ROUGE的计算流程：**  \n",
    "预处理：将生成的摘要和参考摘要进行分词（tokenization），可能还包括小写化、去除停用词等（取决于具体实现）。  \n",
    "计算各个 ROUGE 变体：根据需要，计算 ROUGE-1, ROUGE-2, ROUGE-L 等。  \n",
    "处理多个参考摘要：  \n",
    "如果有多个参考摘要，通常对每个参考摘要分别计算 ROUGE，然后取最大值或平均值作为最终分数。取最大值更常见，因为它衡量的是生成摘要与“任何一个”参考摘要的相似度。  \n",
    "报告结果：通常报告 Precision, Recall, F1 三个值，其中 F1 是最常用的综合指标。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164e27d-5223-4653-b5e3-66c8552bfa52",
   "metadata": {},
   "source": [
    "**ROUGE 的优点**  \n",
    "简单高效：计算速度快，易于实现和自动化。  \n",
    "与人工评价相关性好：大量研究表明，ROUGE 分数（尤其是 ROUGE-1, ROUGE-2, ROUGE-L）与人工评价（如内容完整性、相关性）有较好的相关性。  \n",
    "侧重召回率：非常适合摘要任务，能有效评估信息覆盖度。  \n",
    "有多种变体：可以根据任务需求选择不同的 ROUGE 指标。  \n",
    "**ROUGE 的缺点**   \n",
    "基于表面形式：只看词形匹配，不理解语义。同义词、近义词、释义（paraphrasing）不会被识别为匹配。   \n",
    "忽略语法和流畅性：一个语法错误百出但包含关键词的句子可能获得高分。  \n",
    "对摘要长度敏感：过长的摘要容易获得高召回率（ROUGE-R），但可能包含冗余信息；过短的摘要召回率低。  \n",
    "不评估信息新颖性或逻辑性：无法判断生成的摘要是否引入了原文没有的错误信息（幻觉），或逻辑是否连贯。  \n",
    "依赖参考摘要质量：如果参考摘要本身不全面或有偏差，ROUGE 分数也会受影响。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25839b7c-adf6-4fc6-bec0-b6edc2507382",
   "metadata": {},
   "source": [
    " **ROUGE的适用场景：**  \n",
    "1、文本摘要任务  \n",
    "2、生成文本可能比参考文本短的场景  \n",
    "3、需要衡量生成文本覆盖参考文本信息程度的场景  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myshixunenvironment)",
   "language": "python",
   "name": "myshixunenvironment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
